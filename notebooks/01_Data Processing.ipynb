{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9949ab12-2161-4998-adfb-fd3eb4aba522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540b2d38-0712-4f6b-ae6c-71bcb1d27bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   title   536 non-null    object \n",
      " 1   stars   469 non-null    float64\n",
      " 2   name    536 non-null    object \n",
      " 3   text    536 non-null    object \n",
      " 4   label   536 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 21.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews_updated.csv\")\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b17588b-e295-453e-a98d-4c02ddd7af82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   title   536 non-null    object \n",
      " 1   stars   469 non-null    float64\n",
      " 2   name    536 non-null    object \n",
      " 3   text    536 non-null    object \n",
      " 4   label   536 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 21.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop unnamed junk columns automatically\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28afe7be-713d-425e-895f-f3a9332441a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['author_name', 'photo'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# drop unnecessary columns ie \"author_name\" and \"photo\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauthor_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mphoto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['author_name', 'photo'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# drop unnecessary columns ie \"author_name\" and \"photo\"\n",
    "df = df.drop(columns=[\"author_name\", \"photo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb07e09-825d-4339-a2bb-12932a32480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle duplicates\n",
    "df.duplicated().sum() # no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e795e77-1372-4d0e-b541-c7b9bbc86bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle noise in text column\n",
    "\n",
    "# 1. Remove HTML tags only\n",
    "df[\"clean_text\"] = df[\"text\"].apply(lambda x: re.sub(r\"<.*?>\", \" \", str(x)))\n",
    "\n",
    "# 2. Keep URLs, numbers, promo words intact\n",
    "#    - Allow letters (a-zA-Z), digits (0-9), colons, slashes, dots, hyphens (for urls/phones),\n",
    "#      and @ (for emails/mentions)\n",
    "df[\"clean_text\"] = df[\"clean_text\"].str.replace(r\"[^a-zA-Z0-9\\s:/\\.\\-\\@]\", \" \", regex=True)\n",
    "\n",
    "# 3. Normalize spaces, lowercase\n",
    "df[\"clean_text\"] = df[\"clean_text\"].str.lower().str.strip()\n",
    "df[\"clean_text\"] = df[\"clean_text\"].str.replace(r\"\\s+\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e84ad1-d99f-4c7e-b443-a2ced80cdede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-specific coding\n",
    "\n",
    "# 1. Initialize stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# 2. Keep important words for classification\n",
    "negation_words = {\"not\", \"no\", \"never\"} # if removed, it'll change the meaning\n",
    "promo_words = {\"free\", \"discount\", \"sale\", \"voucher\", \"promo\", \"offer\", \"deal\"}\n",
    "\n",
    "# 3. Adjust stopword list: remove negations and promo words\n",
    "custom_stopwords = stop_words - negation_words - promo_words\n",
    "\n",
    "# 4. Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 5. Define cleaning function\n",
    "def clean_tokens(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in custom_stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# 6. Apply cleaning\n",
    "df[\"processed_text\"] = df[\"clean_text\"].apply(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb429d3-814f-44c5-bd7f-0e3003369a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the clean_text column\n",
    "df = df.drop(columns=[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144da3be-1227-4f2e-b231-4be1f2571c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the cleaned dataframe preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b703b-3771-46e1-b1d9-f9e1ba6de303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
