{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9949ab12-2161-4998-adfb-fd3eb4aba522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540b2d38-0712-4f6b-ae6c-71bcb1d27bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   title   536 non-null    object \n",
      " 1   stars   469 non-null    float64\n",
      " 2   name    536 non-null    object \n",
      " 3   text    536 non-null    object \n",
      " 4   label   536 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 21.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews_updated.csv\")\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b17588b-e295-453e-a98d-4c02ddd7af82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   title   536 non-null    object \n",
      " 1   stars   469 non-null    float64\n",
      " 2   name    536 non-null    object \n",
      " 3   text    536 non-null    object \n",
      " 4   label   536 non-null    object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 21.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop unnamed junk columns automatically\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb07e09-825d-4339-a2bb-12932a32480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle duplicates\n",
    "df.duplicated().sum() # no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e795e77-1372-4d0e-b541-c7b9bbc86bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle noise in text column\n",
    "\n",
    "# 1. Remove HTML tags only\n",
    "df[\"clean_text\"] = df[\"text\"].apply(lambda x: re.sub(r\"<.*?>\", \" \", str(x)))\n",
    "\n",
    "# 2. Keep URLs, numbers, promo words intact\n",
    "#    - Allow letters (a-zA-Z), digits (0-9), colons, slashes, dots, hyphens (for urls/phones),\n",
    "#      and @ (for emails/mentions)\n",
    "df[\"clean_text\"] = df[\"clean_text\"].str.replace(r\"[^a-zA-Z0-9\\s:/\\.\\-\\@]\", \" \", regex=True)\n",
    "\n",
    "# 3. Normalize spaces, lowercase\n",
    "df[\"clean_text\"] = df[\"clean_text\"].str.lower().str.strip()\n",
    "df[\"clean_text\"] = df[\"clean_text\"].str.replace(r\"\\s+\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e84ad1-d99f-4c7e-b443-a2ced80cdede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-specific coding\n",
    "\n",
    "# 1. Initialize stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# 2. Keep important words for classification\n",
    "negation_words = {\"not\", \"no\", \"never\"} # if removed, it'll change the meaning\n",
    "promo_words = {\"free\", \"discount\", \"sale\", \"voucher\", \"promo\", \"offer\", \"deal\"}\n",
    "\n",
    "# 3. Adjust stopword list: remove negations and promo words\n",
    "custom_stopwords = stop_words - negation_words - promo_words\n",
    "\n",
    "# 4. Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 5. Define cleaning function\n",
    "def clean_tokens(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in custom_stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# 6. Apply cleaning\n",
    "df[\"processed_text\"] = df[\"clean_text\"].apply(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb429d3-814f-44c5-bd7f-0e3003369a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the clean_text column\n",
    "df = df.drop(columns=[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144da3be-1227-4f2e-b231-4be1f2571c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the cleaned dataframe preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b703b-3771-46e1-b1d9-f9e1ba6de303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
