{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80107ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vedah\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\vedah\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vedah\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\vedah\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vedah\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\vedah\\anaconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\vedah\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: torch in c:\\users\\vedah\\appdata\\roaming\\python\\python311\\site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: nltk in c:\\users\\vedah\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vedah\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "# Install packages (run once in your notebook environment)\n",
    "!pip install pandas numpy scikit-learn scipy matplotlib wordcloud transformers torch nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745f32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedah\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1) Imports & downloads\n",
    "# ============================================================\n",
    "import re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from transformers import pipeline\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3c5c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data overview ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   business_name    312 non-null    object\n",
      " 1   text             312 non-null    object\n",
      " 2   rating           312 non-null    int64 \n",
      " 3   rating_category  312 non-null    object\n",
      " 4   label            312 non-null    object\n",
      " 5   processed_text   312 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 14.8+ KB\n",
      "None\n",
      "    business_name                                               text  rating  \\\n",
      "0  Abidin Tantuni  It was too oily and the place had problems wit...       2   \n",
      "1  Abidin Tantuni  It was too spicy on my first try; but after a ...       4   \n",
      "2  Abidin Tantuni  it tasted so good that I even ordered and ate ...       5   \n",
      "\n",
      "      rating_category         label  \\\n",
      "0               taste  Clean Review   \n",
      "1  outdoor_atmosphere  Clean Review   \n",
      "2   indoor_atmosphere  Clean Review   \n",
      "\n",
      "                                      processed_text  \n",
      "0                    oily place problem cleanliness.  \n",
      "1  spicy first try bite got used it. taste really...  \n",
      "2            tasted good even ordered ate second one  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2) Load your dataset (follow your reference)\n",
    "# ============================================================\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")  \n",
    "\n",
    "# Drop junk unnamed columns\n",
    "df = df.drop(columns=[c for c in df.columns if str(c).startswith(\"Unnamed\")], errors=\"ignore\")\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\")\n",
    "\n",
    "print(\"=== Data overview ===\")\n",
    "print(df.info())\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f539ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_final\n",
      "Clean review          123\n",
      "Rant without visit     91\n",
      "Advertisement          87\n",
      "Irrelevant content     11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3) Zero-shot + rule overrides\n",
    "# ============================================================\n",
    "labels = [\"Advertisement\", \"Irrelevant content\", \"Rant without visit\", \"Clean review\"]\n",
    "\n",
    "clf_zs = pipeline(\"zero-shot-classification\",\n",
    "                  model=\"typeform/distilbert-base-uncased-mnli\",\n",
    "                  device=-1)  # CPU\n",
    "\n",
    "def zero_shot_batch(texts, batch_size=16):\n",
    "    out = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        chunk = texts[i:i+batch_size]\n",
    "        res = clf_zs(chunk, candidate_labels=labels,\n",
    "                     hypothesis_template=\"This review is {}.\")\n",
    "        if isinstance(res, dict): res = [res]\n",
    "        out.extend([r[\"labels\"][0] for r in res])\n",
    "    return out\n",
    "\n",
    "df[\"policy_pred_zeroshot\"] = zero_shot_batch(df[\"text\"].tolist(), batch_size=16)\n",
    "\n",
    "# --- Rule-based overrides ---\n",
    "PROMO_WORDS = r\"(discount|coupon|promo|promotion|deal|sale|use code|visit|voucher|free)\"\n",
    "ANTI_VISIT = r\"(never been|haven'?t been|did(n't| not) visit|did(n't| not) go|not been there)\"\n",
    "URL_PAT = r\"(http[s]?://|www\\.)\"\n",
    "\n",
    "def override_policy(raw_text, current_label):\n",
    "    s = str(raw_text)\n",
    "    if re.search(URL_PAT, s, re.I) or re.search(PROMO_WORDS, s, re.I):\n",
    "        return \"Advertisement\"\n",
    "    if re.search(ANTI_VISIT, s, re.I):\n",
    "        return \"Rant without visit\"\n",
    "    return current_label\n",
    "\n",
    "df[\"policy_final\"] = [override_policy(t, p) for t, p in zip(df[\"text\"], df[\"policy_pred_zeroshot\"])]\n",
    "print(df[\"policy_final\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c229c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target = label\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4) Choose training target\n",
    "# ============================================================\n",
    "TARGET_COL = \"label\" if \"label\" in df.columns and df[\"label\"].notna().any() else \"policy_final\"\n",
    "print(f\"Training target = {TARGET_COL}\")\n",
    "y = df[TARGET_COL].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e738ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) Split data 80-20\n",
    "# ============================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], y, test_size=0.2, random_state=20, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc78cb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (249, 922) | Test shape: (63, 922)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6) Features (TF-IDF + simple regex)\n",
    "# ============================================================\n",
    "PHONE_PAT = r\"\\b\\+?\\d[\\d\\s\\-]{6,}\\b\"\n",
    "VISIT_WORDS = r\"(i visited|we went|queued|ordered|ate|table|bill|waiter|menu)\"\n",
    "\n",
    "def simple_feats(text):\n",
    "    t = str(text).lower()\n",
    "    return {\n",
    "        \"has_url\": int(bool(re.search(URL_PAT, t))),\n",
    "        \"has_phone\": int(bool(re.search(PHONE_PAT, t))),\n",
    "        \"promo_hit\": int(bool(re.search(PROMO_WORDS, t))),\n",
    "        \"exclam\": str(text).count(\"!\"),\n",
    "        \"allcaps_ratio\": (sum(ch.isupper() for ch in str(text)) / max(1, len(str(text)))),\n",
    "        \"anti_visit\": int(bool(re.search(ANTI_VISIT, t))),\n",
    "        \"visit_words\": int(bool(re.search(VISIT_WORDS, t))),\n",
    "        \"relevance_hint\": 1 - int(bool(re.search(PROMO_WORDS, t))),\n",
    "    }\n",
    "\n",
    "class FeatExtractor(BaseEstimator, TransformerMixin):\n",
    "    KEYS = [\n",
    "        \"has_url\",\"has_phone\",\"promo_hit\",\"exclam\",\n",
    "        \"allcaps_ratio\",\"anti_visit\",\"visit_words\",\"relevance_hint\"\n",
    "    ]\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        # X is an iterable of strings (Series/list)\n",
    "        rows = [simple_feats(x) for x in X]\n",
    "        # Build matrix in a stable, explicit order of KEYS\n",
    "        return np.array([[r[k] for k in self.KEYS] for r in rows], dtype=float)\n",
    "\n",
    "# Text features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=30000, min_df=2)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf.transform(X_test)\n",
    "\n",
    "# Numeric features\n",
    "num_extractor = FeatExtractor()\n",
    "X_train_num = num_extractor.fit_transform(X_train)\n",
    "X_test_num  = num_extractor.transform(X_test)\n",
    "\n",
    "# Combine (sparse hstack keeps memory low)\n",
    "X_train_all = sparse.hstack([X_train_tfidf, sparse.csr_matrix(X_train_num)], format=\"csr\")\n",
    "X_test_all  = sparse.hstack([X_test_tfidf,  sparse.csr_matrix(X_test_num)],  format=\"csr\")\n",
    "\n",
    "print(\"Train shape:\", X_train_all.shape, \"| Test shape:\", X_test_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1839ee5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=2000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7) Train classifier\n",
    "# ============================================================\n",
    "clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "clf.fit(X_train_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6fdc12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RICH MODEL: TF-IDF(3000) + Logistic Regression + numeric regex features===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Advertisement      0.889     1.000     0.941         8\n",
      "        Clean Review      0.975     0.951     0.963        41\n",
      "  Irrelevant Content      0.800     1.000     0.889         8\n",
      "Review without Visit      1.000     0.667     0.800         6\n",
      "\n",
      "            accuracy                          0.937        63\n",
      "           macro avg      0.916     0.904     0.898        63\n",
      "        weighted avg      0.944     0.937     0.935        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8) Evaluate\n",
    "# ============================================================\n",
    "print(\"\\n=== RICH MODEL: TF-IDF(3000) + Logistic Regression + numeric regex features===\")\n",
    "y_pred = clf.predict(X_test_all)\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcdb57f",
   "metadata": {},
   "source": [
    "Accuracy:93.7%\n",
    "\n",
    "Macro Average F1: At 0.898, the macro F1 shows that performance is consistently high across all classes.\n",
    "Weighted Average F1: The weighted F1 of 0.935 indicates the model maintains strong results even when considering class imbalance.\n",
    "\n",
    "**Per Class Analysis**\n",
    "\n",
    "*Advertisement*\n",
    "- Precision = 0.889, Recall = 1.000, F1 = 0.941\n",
    "The model correctly identifies all advertisements (perfect recall). A few non-ads are misclassified as ads, which slightly lowers precision, but overall detection is highly reliable.\n",
    "\n",
    "*Clean Review*\n",
    "- Precision = 0.975, Recall = 0.951, F1 = 0.963\n",
    "Clean reviews are detected with both high precision and recall. This is the best-performing class, showing the model is excellent at recognizing genuine reviews.\n",
    "\n",
    "*Irrelevant Content*\n",
    "- Precision = 0.800, Recall = 1.000, F1 = 0.889\n",
    "All irrelevant reviews are captured (perfect recall), though some clean reviews are mistakenly flagged as irrelevant. This trade-off lowers precision, but ensures that irrelevant content is not missed.\n",
    "\n",
    "*Review without Visit*\n",
    "- Precision = 1.000, Recall = 0.667, F1 = 0.800\n",
    "The model is very cautious with this class, only labeling reviews as “No Visit” when it is highly confident (precision 100%). However, recall is weaker, with one-third of such reviews being missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b98e632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COL = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8ea0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BASELINE: TF-IDF(3000) + Logistic Regression ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Advertisement      0.889     1.000     0.941         8\n",
      "        Clean Review      0.889     0.976     0.930        41\n",
      "  Irrelevant Content      0.833     0.625     0.714         8\n",
      "Review without Visit      1.000     0.500     0.667         6\n",
      "\n",
      "            accuracy                          0.889        63\n",
      "           macro avg      0.903     0.775     0.813        63\n",
      "        weighted avg      0.892     0.889     0.879        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build df2 to mirror your style, using the chosen target\n",
    "df2 = df[[TEXT_COL, TARGET_COL]].rename(columns={TEXT_COL: \"text\", TARGET_COL: \"label\"}).copy()\n",
    "df2[\"text\"] = df2[\"text\"].fillna(\"\")\n",
    "df2[\"label\"] = df2[\"label\"].astype(str)\n",
    "\n",
    "# Vectorize text (baseline)\n",
    "vectorizer_base = TfidfVectorizer(max_features=3000, stop_words=\"english\")\n",
    "X_base = vectorizer_base.fit_transform(df2[\"text\"])\n",
    "y_base = df2[\"label\"]\n",
    "\n",
    "# Split\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    X_base, y_base, test_size=0.2, random_state=20, stratify=y_base\n",
    ")\n",
    "\n",
    "# Logistic Regression baseline\n",
    "logreg_base = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    "    multi_class=\"auto\"\n",
    ")\n",
    "logreg_base.fit(X_train_b, y_train_b)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_b = logreg_base.predict(X_test_b)\n",
    "print(\"\\n=== BASELINE: TF-IDF(3000) + Logistic Regression ===\")\n",
    "print(classification_report(y_test_b, y_pred_b, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abb443",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "Accuracy: 88.9%\n",
    "\n",
    "- Macro average F1: 0.813 which shows that performance across classes is uneven; some classes do much better than others.\n",
    "\n",
    "- Weighted average F1: 0.879 → shows performance is better on frequent classes (like Clean Review) but weaker on rare ones.\n",
    "\n",
    "\n",
    "**Per class Analysis** \n",
    "\n",
    "*Advertisement* \n",
    "\n",
    "- Advertisement Precision = 0.889, Recall = 1.000, F1 = 0.941 \n",
    "The model catches all ads (recall 100%) but a few non-ads are incorrectly predicted as ads (precision <1). Very strong performance here.\n",
    "\n",
    "*Clean review*\n",
    "\n",
    "- Precision = 0.889, Recall = 0.976, F1 = 0.930 \n",
    "Almost all clean reviews are correctly identified. Small precision loss means a handful of non-clean reviews are mislabeled as clean. Overall, this is the best performing class.\n",
    "\n",
    "*Irrelevant content* \n",
    " \n",
    "- Precision = 0.833, Recall = 0.625, F1 = 0.714\n",
    "When the model says “irrelevant,” it’s usually right (precision good). But it misses ~40% of actual irrelevant reviews (low recall). This suggests that the model is not picking up enough signals for this class(maybe due to too few training examples or overlap with “Clean Review”.)\n",
    "\n",
    "*Rant without visit*\n",
    "\n",
    "- Precision = 1.000, Recall = 0.500, F1 = 0.667\n",
    "The model is super cautious as it only labels a review as “No Visit” when it’s very sure (precision = 100%). But it misses half the actual “No Visit” cases (recall 0.5). This is typical when the class has low support as the model learns too little."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa163191",
   "metadata": {},
   "source": [
    "## Overall Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de77a2",
   "metadata": {},
   "source": [
    "**Baseline Model** \n",
    "\n",
    "- Accuracy: 88.9%\n",
    "- Macro F1: 0.813 → performance uneven, weaker on minority classes\n",
    "- Weighted F1: 0.879 → strong overall, biased toward frequent classes (Clean Review)\n",
    "\n",
    "**Rich Model**\n",
    "- Accuracy: 93.7%\n",
    "- Macro F1: 0.898 which is consistently high across all classes\n",
    "- Weighted F1: 0.935 → better balance across frequent and rare categories\n",
    "\n",
    "Summary: The rich model clearly improves accuracy and balances performance across classes compared to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499fd40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
