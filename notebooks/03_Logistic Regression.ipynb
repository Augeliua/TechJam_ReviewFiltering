{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745f32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedah\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports & downloads\n",
    "import re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from transformers import pipeline\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "#nltk.download(\"stopwords\", quiet=True)\n",
    "#nltk.download(\"wordnet\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3c5c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           536 non-null    object \n",
      " 1   stars           469 non-null    float64\n",
      " 2   name            536 non-null    object \n",
      " 3   text            536 non-null    object \n",
      " 4   label           536 non-null    object \n",
      " 5   processed_text  536 non-null    object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 25.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2) Load dataset \n",
    "df = pd.read_csv(\"cleaned_dataset.csv\") \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f539ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED = (\"irrelevant\", \"advertisement\", \"rant\", \"feedback\")\n",
    "REMAP = {\n",
    "    # ads\n",
    "    \"advertisement\":\"advertisement\",\"advert\":\"advertisement\",\"ad\":\"advertisement\",\"ads\":\"advertisement\",\n",
    "    # irrelevant family\n",
    "    \"irrelevant\":\"irrelevant\",\"irrelevant content\":\"irrelevant\",\"review without visit\":\"irrelevant\",\n",
    "    \"no visit\":\"irrelevant\",\"not a review\":\"irrelevant\",\"off topic\":\"irrelevant\",\"off-topic\":\"irrelevant\",\"anti_visit\":\"irrelevant\",\n",
    "    # rant\n",
    "    \"rant\":\"rant\",\"angry rant\":\"rant\",\"negative rant\":\"rant\",\n",
    "    # feedback / clean\n",
    "    \"clean review\":\"feedback\",\"review\":\"feedback\",\"informative\":\"feedback\",\"neutral\":\"feedback\",\n",
    "    \"feedback\":\"feedback\",\"genuine\":\"feedback\",\"constructive\":\"feedback\",\"helpful\":\"feedback\",\"positive\":\"feedback\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56450fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Rule-based overrides (stay within allowed labels) ---\n",
    "PROMO_WORDS = re.compile(r\"(discount|coupon|promo|promotion|deal|sale|use code|voucher|free)\", re.I)\n",
    "ANTI_VISIT   = re.compile(r\"(never been|haven'?t been|did(?:n['’]t| not) visit|did(?:n['’]t| not) go|not been there)\", re.I)\n",
    "URL_PAT      = re.compile(r\"(http[s]?://|www\\.)\", re.I)\n",
    "\n",
    "def override_policy(raw_text, current_label):\n",
    "    s = raw_text if isinstance(raw_text, str) else \"\"\n",
    "    if URL_PAT.search(s) or PROMO_WORDS.search(s):\n",
    "        return \"Advertisement\"\n",
    "    if ANTI_VISIT.search(s):\n",
    "        return \"Review without visit\"\n",
    "    # keep model prediction\n",
    "    return current_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c229c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: {'feedback': 382, 'rant': 60, 'advertisement': 60, 'irrelevant': 34}\n"
     ]
    }
   ],
   "source": [
    "def remap_lbl(x):\n",
    "    s = \"\" if pd.isna(x) else str(x).strip().lower()\n",
    "    return REMAP.get(s, \"feedback\")\n",
    "\n",
    "if \"label\" not in df.columns:\n",
    "    raise ValueError(\"Expected a 'label' column in df\")\n",
    "\n",
    "df[\"label\"] = df[\"label\"].map(remap_lbl)\n",
    "bad = set(df[\"label\"].unique()) - set(ALLOWED)\n",
    "assert not bad, f\"Unexpected labels after remap: {bad}\"\n",
    "print(\"Label distribution:\", df[\"label\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca94ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COL = \"processed_text\" if \"processed_text\" in df.columns else \"text\"\n",
    "X_text = df[TEXT_COL].fillna(\"\").astype(str)\n",
    "y = df[\"label\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e738ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], y, test_size=0.2, random_state=20, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc78cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 6) Feature extraction (TF-IDF + simple regex) =====\n",
    "URL_PAT     = re.compile(r\"(http[s]?://|www\\.)\", re.I)\n",
    "PROMO_WORDS = re.compile(r\"(discount|coupon|promo|promotion|deal|sale|use code|voucher|free)\", re.I)\n",
    "ANTI_VISIT  = re.compile(r\"(never been|haven'?t been|did(?:n['’]t| not) visit|did(?:n['’]t| not) go|not been there)\", re.I)\n",
    "PHONE_PAT   = re.compile(r\"\\b\\+?\\d[\\d\\s\\-]{6,}\\b\", re.I)\n",
    "VISIT_WORDS = re.compile(r\"(i visited|we went|queued|ordered|ate|table|bill|waiter|menu)\", re.I)\n",
    "\n",
    "def simple_feats(text):\n",
    "    s = \"\" if text is None else str(text)\n",
    "    s_low = s.lower()\n",
    "    allcaps_ratio = sum(ch.isupper() for ch in s) / max(1, len(s))\n",
    "    return {\n",
    "        \"has_url\":        int(bool(URL_PAT.search(s_low))),\n",
    "        \"has_phone\":      int(bool(PHONE_PAT.search(s_low))),\n",
    "        \"promo_hit\":      int(bool(PROMO_WORDS.search(s_low))),\n",
    "        \"exclam\":         s.count(\"!\"),\n",
    "        \"allcaps_ratio\":  allcaps_ratio,\n",
    "        \"anti_visit\":     int(bool(ANTI_VISIT.search(s_low))),\n",
    "        \"visit_words\":    int(bool(VISIT_WORDS.search(s_low))),\n",
    "        \"relevance_hint\": 0 if PROMO_WORDS.search(s_low) else 1,\n",
    "    }\n",
    "class FeatExtractor(BaseEstimator, TransformerMixin):\n",
    "    KEYS = [\"has_url\",\"has_phone\",\"promo_hit\",\"exclam\",\n",
    "            \"allcaps_ratio\",\"anti_visit\",\"visit_words\",\"relevance_hint\"]\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        rows = [simple_feats(x) for x in X]\n",
    "        return np.array([[r[k] for k in self.KEYS] for r in rows], dtype=float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed6688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (428, 4098) | Test shape: (108, 4098)\n"
     ]
    }
   ],
   "source": [
    "# ===== D) TF-IDF + numeric features =====\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    max_features=30000,\n",
    "    min_df=2,\n",
    "    sublinear_tf=True,\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True\n",
    ")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf.transform(X_test)\n",
    "\n",
    "num_extractor = FeatExtractor()\n",
    "X_train_num = num_extractor.fit_transform(X_train)\n",
    "X_test_num  = num_extractor.transform(X_test)\n",
    "\n",
    "X_train_all = sparse.hstack([X_train_tfidf, sparse.csr_matrix(X_train_num)], format=\"csr\")\n",
    "X_test_all  = sparse.hstack([X_test_tfidf,  sparse.csr_matrix(X_test_num)],  format=\"csr\")\n",
    "print(\"Train shape:\", X_train_all.shape, \"| Test shape:\", X_test_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd0baaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=2000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=20, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=2000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=20, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=2000,\n",
       "                   multi_class='multinomial', random_state=20, solver='saga')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== E) Train Logistic Regression =====\n",
    "clf = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    multi_class=\"multinomial\",\n",
    "    class_weight=\"balanced\",\n",
    "    C=1.0,\n",
    "    max_iter=2000,\n",
    "    random_state=20\n",
    ")\n",
    "clf.fit(X_train_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6fdc12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL ON ENTIRE DATASET\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "advertisement      1.000     1.000     1.000        12\n",
      "     feedback      0.950     0.987     0.968        77\n",
      "   irrelevant      0.857     0.857     0.857         7\n",
      "         rant      1.000     0.750     0.857        12\n",
      "\n",
      "     accuracy                          0.954       108\n",
      "    macro avg      0.952     0.899     0.921       108\n",
      " weighted avg      0.955     0.954     0.952       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8) Evaluate\n",
    "print(\"\\n=== MODEL ON ENTIRE DATASET\")\n",
    "y_pred = clf.predict(X_test_all)\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abb443",
   "metadata": {},
   "source": [
    "**Logistic Regressio on entire dataset**\n",
    "\n",
    "Accuracy: 95.4%\n",
    "\n",
    "- Macro average F1: 0.921 which shows that performance across classes quite even.\n",
    "\n",
    "- Weighted average F1: 0.952 shows performance is better on frequent classes (like Feedback) but weaker on minority ones.\n",
    "\n",
    "\n",
    "**Per class Analysis** \n",
    "\n",
    "*Advertisement* \n",
    "\n",
    "- Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
    "- There is perfect separation and it shows that the URLS or promo cues are working\n",
    "\n",
    "*Feedback*\n",
    "\n",
    "- Precision = 0.950, Recall = 0.987, F1 = 0.968 \n",
    "-  Relatively strong and only a few borderline negatives slip in as feedback (minor false positives elsewhere)\n",
    "\n",
    "*Irrelevant content* \n",
    " \n",
    "- Precision = 0.857, Recall = 0.857, F1 = 0.857\n",
    "- Solid given small amount of data, there are some overlap with feedback\n",
    "\n",
    "*Rant*\n",
    "\n",
    "- Precision = 1.000, Recall = 0.750, F1 = 0.857\n",
    "- Extremely precise but misses ~25% of true rants (often toned-down negatives → feedback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49bfeb49-d332-4811-bea6-ecb07abacf6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row #324\n",
      "Text: Always have the best time at Universal Studios. âœ¨ Compared to Disneyland though, the rides here feel a lot [...]\n",
      "Pred: feedback | Conf: 0.47\n",
      "Flags: {'advertisement_flag': 0, 'irrelevant_flag': 0, 'rant_flag': 0, 'feedback_flag': 1}\n",
      "--------------------------------------------------------------------------------\n",
      "Row #328\n",
      "Text: Ordered takeaway. There's no omelette packed with it. Not happy with the service.\n",
      "Pred: feedback | Conf: 0.769\n",
      "Flags: {'advertisement_flag': 0, 'irrelevant_flag': 0, 'rant_flag': 0, 'feedback_flag': 1}\n",
      "--------------------------------------------------------------------------------\n",
      "Row #129\n",
      "Text: Hotel Calmo Bugis is in an ideal location, surrounded by lovely Chinese restaurants and offering plenty to [...]\n",
      "Pred: feedback | Conf: 0.465\n",
      "Flags: {'advertisement_flag': 0, 'irrelevant_flag': 0, 'rant_flag': 0, 'feedback_flag': 1}\n",
      "--------------------------------------------------------------------------------\n",
      "Row #521\n",
      "Text: Unbelievably bad experience. THEY ARGUED INSTEAD OF FIXING IT! I regret coming here!\n",
      "Pred: rant | Conf: 0.47\n",
      "Flags: {'advertisement_flag': 0, 'irrelevant_flag': 0, 'rant_flag': 1, 'feedback_flag': 0}\n",
      "--------------------------------------------------------------------------------\n",
      "Row #380\n",
      "Text: Waited 35 mins for a average omu rice. That's after queuing to get in. Edible food just dun come off you are [...]\n",
      "Pred: feedback | Conf: 0.513\n",
      "Flags: {'advertisement_flag': 0, 'irrelevant_flag': 0, 'rant_flag': 0, 'feedback_flag': 1}\n",
      "--------------------------------------------------------------------------------\n",
      "Saved predictions to predictions_4labels.csv\n"
     ]
    }
   ],
   "source": [
    "# ==== Predict on ALL rows with your 4-label schema ====\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# 1) Canonicalize labels (robust to casing/variants)\n",
    "ALLOWED = (\"irrelevant\",\"advertisement\",\"rant\",\"feedback\")\n",
    "REMAP = {\n",
    "    # ads\n",
    "    \"advertisement\":\"advertisement\",\"advert\":\"advertisement\",\"ad\":\"advertisement\",\"ads\":\"advertisement\",\n",
    "    # irrelevant family\n",
    "    \"irrelevant\":\"irrelevant\",\"irrelevant content\":\"irrelevant\",\"review without visit\":\"irrelevant\",\n",
    "    \"no visit\":\"irrelevant\",\"off topic\":\"irrelevant\",\"off-topic\":\"irrelevant\",\"anti_visit\":\"irrelevant\",\n",
    "    # rant\n",
    "    \"rant\":\"rant\",\"angry rant\":\"rant\",\"negative rant\":\"rant\",\n",
    "    # feedback / clean review\n",
    "    \"clean review\":\"feedback\",\"review\":\"feedback\",\"informative\":\"feedback\",\"neutral\":\"feedback\",\"feedback\":\"feedback\"\n",
    "}\n",
    "def canon(x):\n",
    "    s = \"\" if x is None else str(x).strip().lower()\n",
    "    return REMAP.get(s, \"feedback\")\n",
    "\n",
    "# 2) Choose text column and build feature matrix for all rows\n",
    "TEXT_COL = \"processed_text\" if \"processed_text\" in df.columns else \"text\"\n",
    "X_all_tfidf = tfidf.transform(df[TEXT_COL].fillna(\"\").astype(str))\n",
    "X_all_num   = num_extractor.transform(df[TEXT_COL].fillna(\"\").astype(str))\n",
    "X_all       = sparse.hstack([X_all_tfidf, sparse.csr_matrix(X_all_num)], format=\"csr\")\n",
    "\n",
    "# 3) Predict labels + confidence\n",
    "raw_pred = clf.predict(X_all)\n",
    "proba    = clf.predict_proba(X_all)\n",
    "df[\"predicted_label\"]        = [canon(p) for p in raw_pred]\n",
    "df[\"prediction_confidence\"]  = proba.max(axis=1)\n",
    "\n",
    "# 4) Ensure only the 4 labels appear\n",
    "assert set(df[\"predicted_label\"].unique()).issubset(ALLOWED), \\\n",
    "    f\"Unexpected labels: {set(df['predicted_label'].unique()) - set(ALLOWED)}\"\n",
    "\n",
    "# 5) One-hot flag columns for your schema\n",
    "label_to_flagcol = {\n",
    "    \"advertisement\": \"advertisement_flag\",\n",
    "    \"irrelevant\":    \"irrelevant_flag\",\n",
    "    \"rant\":          \"rant_flag\",\n",
    "    \"feedback\":      \"feedback_flag\",\n",
    "}\n",
    "for lab, col in label_to_flagcol.items():\n",
    "    df[col] = (df[\"predicted_label\"] == lab).astype(int)\n",
    "\n",
    "# 6) Optional: show a few samples\n",
    "from textwrap import shorten\n",
    "to_show = [\"text\", \"predicted_label\", \"prediction_confidence\"] + list(label_to_flagcol.values())\n",
    "for idx, row in df.sample(5, random_state=20)[to_show].iterrows():\n",
    "    print(f\"Row #{idx}\")\n",
    "    print(\"Text:\", shorten(str(row[\"text\"]), width=120))\n",
    "    print(\"Pred:\", row[\"predicted_label\"], \"| Conf:\", round(float(row[\"prediction_confidence\"]), 3))\n",
    "    print(\"Flags:\", {k: int(row[k]) for k in label_to_flagcol.values()})\n",
    "    print(\"-\"*80)\n",
    "\n",
    "# 7) (Optional) save out\n",
    "df.to_csv(\"predictions_4labels.csv\", index=False)\n",
    "print(\"Saved predictions to predictions_4labels.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa163191",
   "metadata": {},
   "source": [
    "## Overall Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de77a2",
   "metadata": {},
   "source": [
    "Overall accuracy 95.4% (macro-F1 0.921, weighted-F1 0.952). Biggest gap is rant recal hence adding more aggressive/negative examples and features for profanity/strong sentiment or keeping casing/punctuation in the features tends to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74b45781-7094-4177-824f-299b62952d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'rich_model_pipeline.joblib'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_bundle = {\n",
    "    \"model\": clf,\n",
    "    \"vectorizer\": tfidf,\n",
    "    \"regex_feats\": num_extractor,\n",
    "    \"label_to_flagcol\": {\n",
    "        \"Advertisement\": \"Advertisement_Flag\",\n",
    "        \"Irrelevant Content\": \"Irrelevant_Content_Flag\",\n",
    "        \"Review without visit\": \"Review_without_Visit_Flag\",\n",
    "        \"Clean Review\": \"Clean_Review_Flag\",\n",
    "    }\n",
    "}\n",
    "joblib.dump(model_bundle, \"rich_model_pipeline.joblib\")\n",
    "print(\"Model saved as 'rich_model_pipeline.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
