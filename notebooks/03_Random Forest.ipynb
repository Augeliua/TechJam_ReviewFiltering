{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d32f8c-dcd5-4437-8e8f-4fefb7cf5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ad6ef8-7b72-41a1-924a-85664ffca213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2c0b61-fdd2-4a15-ac15-f347377f2ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Advertisement       0.78      1.00      0.88         7\n",
      "        Clean Review       0.86      1.00      0.92        42\n",
      "  Irrelevant Content       1.00      0.50      0.67         8\n",
      "Review without Visit       1.00      0.17      0.29         6\n",
      "\n",
      "            accuracy                           0.86        63\n",
      "           macro avg       0.91      0.67      0.69        63\n",
      "        weighted avg       0.88      0.86      0.82        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer(max_features=3000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['processed_text'])\n",
    "y = df['label']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601e52a-cf59-4cbe-abe3-a4d978fdf298",
   "metadata": {},
   "source": [
    "# Evaluation of Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3c1de-1908-441e-a673-8082faf84ca1",
   "metadata": {},
   "source": [
    "**Random Forest:** \n",
    "\n",
    "Accuracy: 86%\n",
    "\n",
    "- Macro average F1 score: 0.69, showing moderate overall performance when treating all four classes equally.\n",
    "\n",
    "- Weighted average F1 score: 0.82, higher than the macro average, meaning the model performs better on the majority classes.\n",
    "\n",
    "**Per Class Analysis:**\n",
    "\n",
    "*Advertisement*\n",
    "- High recall (1.00) indicates the model catches all ads, but precision (0.78) shows some false positives. Overall performance is strong.\n",
    "\n",
    "*Clean Review*\n",
    "- Best-performing class with both precision (0.86) and recall (1.00) high, showing the model reliably recognizes normal reviews.\n",
    "\n",
    "*Irrelevant Content*\n",
    "- Precision is perfect (1.00), but recall drops to 0.50, meaning the model predicts Irrelevant Content correctly when it does, but misses half of the true cases.\n",
    "\n",
    "*Review without Visit*\n",
    "- Weakest class with very low recall (0.17) despite perfect precision (1.00), suggesting the model rarely detects such cases. This class needs more training data or clearer distinguishing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901a21ea-0a42-4282-b97b-fce8e481cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = vectorizer.transform(df['processed_text'])\n",
    "\n",
    "# Get predicted probabilities\n",
    "proba = model.predict_proba(X_unlabeled)\n",
    "\n",
    "# Get label names in correct order\n",
    "labels = model.classes_\n",
    "\n",
    "# Add top prediction and its probability\n",
    "df['predicted_label'] = model.predict(X_unlabeled)\n",
    "df['prediction_confidence'] = proba.max(axis=1)  # highest probability for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f49f722-9e9c-4c62-b0ae-aa952b3e02a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #228\n",
      "Text:\n",
      "Buy 2 get 1 free pizza! www.pizzabogo.com\n",
      "Prediction Confidence: 0.94\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      1\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       0\n",
      "--------------------------------------------------------------------------------\n",
      "Review #9\n",
      "Text:\n",
      "Great service and reasonable prices. Recommend!\n",
      "Prediction Confidence: 0.93\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n",
      "Review #57\n",
      "Text:\n",
      "Prices was high.\n",
      "Prediction Confidence: 0.85\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n",
      "Review #60\n",
      "Text:\n",
      "The place is nice; the employees are good. The food is delicious but the human pilfering for extra charge caused me to give it 1 point.\n",
      "Prediction Confidence: 0.99\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n",
      "Review #25\n",
      "Text:\n",
      "Nice atmosphere!\n",
      "Prediction Confidence: 0.97\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n",
      "Review #63\n",
      "Text:\n",
      "Every time I go; the prices change; I don't like it. But even for the treats; you can go; which comes as many appetizers; tea; etc. as you want.\n",
      "Prediction Confidence: 0.86\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n",
      "Review #93\n",
      "Text:\n",
      "Here you can find by far the best 4-cheese pizza you can eat in Bodrum. On top of that; you may have reasons to come back again and again with the unusual taste and presentation of the magnolia.\n",
      "Prediction Confidence: 0.98\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n",
      "Review #185\n",
      "Text:\n",
      "First of all; the atmosphere is nice; but there should be a solution for flies in the open air; such as fans that blow water. As for the pizza; although the view is beautiful; neither my wife and I did not like the pizza; unfortunately; the sauces that came only to pour on the pizza were good.\n",
      "Prediction Confidence: 0.98\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n",
      "Review #260\n",
      "Text:\n",
      "Try our seafood special! Order now at www.seafoodpromo.com\n",
      "Prediction Confidence: 0.9\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      1\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       0\n",
      "--------------------------------------------------------------------------------\n",
      "Review #46\n",
      "Text:\n",
      "The venue is beautiful. Food/desserts taste good. I loved the Popcorn Shrimp from the hot appetizers. I loved Pose Armut. Overall good price/performance.\n",
      "Prediction Confidence: 0.99\n",
      "Flags (1=true, 0=false):\n",
      "  Advertisement_Flag:      0\n",
      "  Irrelevant_Content_Flag: 0\n",
      "  Rant_without_Visit_Flag: 0\n",
      "  Clean_Review_Flag:       1\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1) Define mapping from label -> flag column name\n",
    "label_to_flagcol = {\n",
    "    \"Advertisement\": \"Advertisement_Flag\",\n",
    "    \"Irrelevant Content\": \"Irrelevant_Content_Flag\",\n",
    "    \"Rant without visit\": \"Rant_without_Visit_Flag\",\n",
    "    \"Clean Review\": \"Clean_Review_Flag\",\n",
    "}\n",
    "\n",
    "# 2) Ensure we have predicted labels on df\n",
    "if \"predicted_label\" not in df.columns:\n",
    "    df[\"predicted_label\"] = pd.Series([labels[i] for i in proba.argmax(axis=1)], index=df.index)\n",
    "\n",
    "# >>> NEW: add prediction_confidence (highest probability per row) <<<\n",
    "df[\"prediction_confidence\"] = proba.max(axis=1)\n",
    "\n",
    "# 3) Create/overwrite the 4 flag columns on **df**\n",
    "for lab, col in label_to_flagcol.items():\n",
    "    df[col] = (df[\"predicted_label\"] == lab).astype(int)\n",
    "\n",
    "# 4) For printing, select 10 random rows from df so flags are present\n",
    "to_print = df.sample(10, random_state=42)[[\"text\", \"prediction_confidence\"] + list(label_to_flagcol.values())]\n",
    "\n",
    "# 5) Print nicely (flags + confidence)\n",
    "for idx, row in to_print.iterrows():\n",
    "    print(f\"Review #{idx}\")\n",
    "    print(f\"Text:\\n{row['text']}\")\n",
    "    print(f\"Prediction Confidence: {row['prediction_confidence']}\")\n",
    "    print(\"Flags (1=true, 0=false):\")\n",
    "    print(f\"  Advertisement_Flag:      {row['Advertisement_Flag']}\")\n",
    "    print(f\"  Irrelevant_Content_Flag: {row['Irrelevant_Content_Flag']}\")\n",
    "    print(f\"  Rant_without_Visit_Flag: {row['Rant_without_Visit_Flag']}\")\n",
    "    print(f\"  Clean_Review_Flag:       {row['Clean_Review_Flag']}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01643952-d973-4493-afcc-c425f7361564",
   "metadata": {},
   "source": [
    "# Comparison with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0d4a5-130e-437a-b871-d2fd49e89bcc",
   "metadata": {},
   "source": [
    "Although Logistic Regression achieved slightly higher overall accuracy and F1-scores in this experiment, Random Forest can be considered the better model from a theoretical standpoint because it captures non-linear feature interactions, is more robust to noisy high-dimensional TF-IDF data, and naturally handles class imbalance betterâ€”evidenced by its higher recall on the critical Advertisement class. In addition, Random Forest offers interpretability through feature importance and greater scalability as the dataset grows, making it a more generalizable and future-proof choice for real-world deployment compared to the linear constraints of Logistic Regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
